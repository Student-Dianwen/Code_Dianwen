{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VvX9DtGvFXlc",
    "outputId": "1dfef802-5dcf-4626-96f6-a25d4e406178"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-03T14:32:17.063945Z",
     "iopub.status.busy": "2025-04-03T14:32:17.063471Z",
     "iopub.status.idle": "2025-04-03T14:32:17.411746Z",
     "shell.execute_reply": "2025-04-03T14:32:17.411193Z",
     "shell.execute_reply.started": "2025-04-03T14:32:17.063912Z"
    },
    "id": "8PzELvdPE_iQ",
    "outputId": "681e1384-24aa-4d10-d28c-ee5f6806acde",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conjunto de entrenamiento: 16026 | conjunto de validación: 4007 | conjunto de pruebas: 8586\n"
     ]
    }
   ],
   "source": [
    "# === 3. 导入模块 ===\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# os.environ['WANDB_API_KEY'] = '255fab36462f5587d825c69b9d5b53a852a2c4d3'  # 替换为你的实际 API 密钥\n",
    "os.environ['WANDB_MODE'] = 'disabled'\n",
    "\n",
    "# === 4. 数据加载与预处理 ===\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    texts = df['text'].tolist()\n",
    "    labels = df['Y'].tolist()\n",
    "    return texts, labels\n",
    "\n",
    "# 路径配置（请确保文件已上传到Google Drive）\n",
    "train_file = \"/content/drive/MyDrive/Colab Notebooks/sarcasm/sarcasm_train.csv\"\n",
    "test_file = \"/content/drive/MyDrive/Colab Notebooks/sarcasm/sarcasm_test.csv\"\n",
    "\n",
    "# 加载数据\n",
    "train_texts, train_labels = load_data(train_file)\n",
    "test_texts, test_labels = load_data(test_file)\n",
    "\n",
    "# 分割训练集/验证集\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"conjunto de entrenamiento: {len(train_texts)} | conjunto de validación: {len(val_texts)} | conjunto de pruebas: {len(test_texts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371,
     "referenced_widgets": [
      "66f8166e64914aebb792e9a2e67a1301",
      "ba713d97edb94f2ba375a5eea74dbf93",
      "d4e9f339f6ad48509922aaadbab05cdc",
      "3b96dd43a69147c5bf4865aac51d1e26",
      "0fb405e66c514420a80d0dfdad9c6c16",
      "f919dec1d35c4c38bed235844dd24ff2",
      "ad79efdfbb484efe90d8c4bb10c9da04",
      "3b86a128d730485ab2b233798a30abbe",
      "d7979179b1524ef1aae454c723954b94",
      "23886ba4f0ee42969a08a3f1529267ea",
      "a7da3b26af144dafab25384c9972275f",
      "f5e45b89cd224909b1435ca4c752e80e",
      "06ca16918f664b7480cbdf81dfb56bd3",
      "0ff9d731e18d4fcba58eb55af61143bb",
      "fe7bffc861c04f20a13d8648326cf3fe",
      "f95d6f4499274fb2888af58398d845b3",
      "9000a97c925f414eaa50986597ff282d",
      "d7faa11e441b45ce98320c9cfa84ac26",
      "ff54d8580f2847fb95cc3e8989afbeba",
      "7b373d3992c14075b09c56b44cc7523c",
      "0448c2fd7dac4506aa682cb9100bff3b",
      "611553804645450bb879cff5e6a31214",
      "f8a2b67a950042f59682b95d0e9dfacf",
      "14f2ba3a0208439b84e3bd9daa7b92ec",
      "4dd5fc885a104b2da4c6aea7eacd7bf7",
      "6329495e4ac4482ea161fa07fa00f24c",
      "de520754853448b8a2c215e62b6baa9f",
      "0ddb22a4bb414ffdb3314311bdcbd554",
      "f378f883fbe2482ab49af0549976865a",
      "c4fe05a9225c46d8bb56041f9ca93a5f",
      "1319a944c0f04189bb6a8d699afdc162",
      "5a634c52fd8e493bad3ad26128ae6526",
      "336fcf601a9d416cb47d94fbf14fba64",
      "8414015222cd4720a48d99e62f4befbb",
      "4c85f37d5d5c40adbc32d9d8bb132d8d",
      "17afb7853d46471b9fa6e74447eb2be0",
      "d513ad64fc19436596b1a606c4051b8d",
      "e9b276c3c09d41349391774e6a09b865",
      "f6a777f7deb54efd80a87ac8c7ace241",
      "477f0bf9d5a845039bb705abc63d919f",
      "3d6c8e46cca542858949f10abb60f776",
      "2971a830049442cf8cbae86605406559",
      "2e4f9dbf266b4caa9eb056299bb1d345",
      "b14759c3e7924ce2a7c2637f59fad594",
      "932023af60ee47829c1202567f4f7c61",
      "828bb80f6c9f4ee2ac9ea2b22383ece6",
      "889663e74903468c8d39ec5e6c4375be",
      "73b7bcfe1f774c1ab5d747d7a3a2236c",
      "2b0596c622ee4360923df4d4845fe9e5",
      "fc82a7d3572248778b7501ee57e803d5",
      "d0b971da5a4544058b24e2d5f260de7a",
      "6d4ba3ab1a2a4c03901527847d2a20e3",
      "03e24b511ab7461d8a5d367c743e561f",
      "82af01f5f84b4f17b28e7b906a5bddde",
      "e9bb4f3078cf4e73b2630ecab3f493c7"
     ]
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-03T14:32:23.282184Z",
     "iopub.status.busy": "2025-04-03T14:32:23.281860Z",
     "iopub.status.idle": "2025-04-03T14:32:23.285122Z",
     "shell.execute_reply": "2025-04-03T14:32:23.284676Z",
     "shell.execute_reply.started": "2025-04-03T14:32:23.282164Z"
    },
    "id": "Nw1S4dS7E_iR",
    "outputId": "0576fced-5331-4c4d-9c73-4b6e5958df9f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f8166e64914aebb792e9a2e67a1301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e45b89cd224909b1435ca4c752e80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a2b67a950042f59682b95d0e9dfacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8414015222cd4720a48d99e62f4befbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932023af60ee47829c1202567f4f7c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "import torch\n",
    "\n",
    "# === 5. BERT专用预处理 ===\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)          # 移除URL\n",
    "    text = re.sub(r'\\b(not|no|never)\\b\\s*', r'\\1_', text)  # 处理否定词\n",
    "    return text.strip()\n",
    "\n",
    "# 清洗数据\n",
    "cleaned_train = [preprocess(text) for text in train_texts]\n",
    "cleaned_val = [preprocess(text) for text in val_texts]\n",
    "cleaned_test = [preprocess(text) for text in test_texts]\n",
    "\n",
    "# 转换为Dataset格式\n",
    "class SarcasmDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128,  # 讽刺文本通常较短\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: v[idx] for k, v in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = SarcasmDataset(cleaned_train, train_labels)\n",
    "val_dataset = SarcasmDataset(cleaned_val, val_labels)\n",
    "test_dataset = SarcasmDataset(cleaned_test, test_labels)\n",
    "\n",
    "# === 6. 模型配置与训练 ===\n",
    "model_save_path = \"/content/drive/MyDrive/Colab Notebooks/model/sarcasm\"\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "# 加载预训练模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=2,\n",
    "    attention_probs_dropout_prob=0.1  # 增加Dropout防止过拟合\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "vFJEyFS2E_iS",
    "outputId": "982d6106-3eb3-4c49-a234-dcd010734e85",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10020' max='10020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10020/10020 33:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.291900</td>\n",
       "      <td>0.286147</td>\n",
       "      <td>0.895433</td>\n",
       "      <td>0.920091</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.884985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.354835</td>\n",
       "      <td>0.907162</td>\n",
       "      <td>0.894956</td>\n",
       "      <td>0.910100</td>\n",
       "      <td>0.902465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.519682</td>\n",
       "      <td>0.913651</td>\n",
       "      <td>0.922362</td>\n",
       "      <td>0.892121</td>\n",
       "      <td>0.906989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.573443</td>\n",
       "      <td>0.918642</td>\n",
       "      <td>0.906072</td>\n",
       "      <td>0.923321</td>\n",
       "      <td>0.914615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.644421</td>\n",
       "      <td>0.918393</td>\n",
       "      <td>0.918630</td>\n",
       "      <td>0.907456</td>\n",
       "      <td>0.913009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT Results for Sarcasm Detection:\n",
      "Accuracy: 0.9115 | Precision: 0.9031 | Recall: 0.9115 | F1-Score: 0.9073\n"
     ]
    }
   ],
   "source": [
    "# 训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_save_path,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,          # 更高的学习率\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=5,          # 增加训练轮次\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True, # 根据验证集加载最优模型\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "\n",
    "# 添加早停机制\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# 执行训练\n",
    "trainer.train()\n",
    "\n",
    "# 保存最佳模型\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "# === 7. 模型评估 ===\n",
    "predictions = trainer.predict(test_dataset)\n",
    "bert_preds = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# 计算指标\n",
    "accuracy = accuracy_score(test_labels, bert_preds)\n",
    "precision = precision_score(test_labels, bert_preds)\n",
    "recall = recall_score(test_labels, bert_preds)\n",
    "f1 = f1_score(test_labels, bert_preds)\n",
    "\n",
    "print(f\"\\nBERT Results for Sarcasm Detection:\")\n",
    "print(f\"Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
