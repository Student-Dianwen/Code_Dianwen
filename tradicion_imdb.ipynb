{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5867f0-f560-4318-9ac0-e022b649b471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:27:16.229009800Z",
     "start_time": "2025-03-25T19:27:05.500566500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 20000\n",
      "Tamaño del conjunto de validación: 5000\n",
      "Tamaño del conjunto de pruebas: 25000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取IMDb评论数据集\n",
    "def read_imdb(data_dir, is_train):\n",
    "    data, labels = [], []\n",
    "    for label in ('pos', 'neg'):\n",
    "        folder_name = os.path.join(data_dir, 'train' if is_train else 'test', label)\n",
    "        for file in os.listdir(folder_name):\n",
    "            with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n', '')\n",
    "                data.append(review)\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    return data, labels\n",
    "\n",
    "# 加载数据\n",
    "data_dir = \"D:/Data/aclImdb/\"\n",
    "train_texts, train_labels = read_imdb(data_dir, is_train=True)\n",
    "test_texts, test_labels = read_imdb(data_dir, is_train=False)\n",
    "\n",
    "# 分割训练集和验证集（可选）\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", len(train_texts))\n",
    "print(\"Tamaño del conjunto de validación:\", len(val_texts))\n",
    "print(\"Tamaño del conjunto de pruebas:\", len(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "384ace30fe6a9933",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T20:21:34.647431500Z",
     "start_time": "2025-03-25T20:18:35.019142700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor umbral en validación: 0.45 (F1-Score: 0.7385)\n",
      "\n",
      "=== Rendimiento final de VADER en IMDb ===\n",
      "Accuracy: 0.7117 | Precision: 0.6737 | Recall: 0.8211 | F1-Score: 0.7401\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# 初始化VADER分析器\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# === 1. 改进的预处理函数 ===\n",
    "def preprocess(text):\n",
    "    \"\"\"保留情感关键标点，移除HTML标签和无关符号\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<br\\s*/?>', ' ', text)       # 优化HTML标签处理\n",
    "    text = re.sub(r'([!?])\\1+', r'\\1', text)    # 合并重复标点（如\"!!!\"→\"!\"）\n",
    "    text = re.sub(r'[^a-zA-Z\\s!?]', '', text)   # 保留字母和关键标点\n",
    "    return text.strip()\n",
    "\n",
    "# === 2. 数据清洗 ===\n",
    "# 清洗验证集和测试集\n",
    "cleaned_val_texts = [preprocess(text) for text in val_texts]\n",
    "cleaned_test_texts = [preprocess(text) for text in test_texts]\n",
    "\n",
    "# === 3. 改进的阈值搜索（基于验证集） ===\n",
    "def find_best_threshold(y_true, texts):\n",
    "    thresholds = np.arange(-0.5, 0.5, 0.05)  # 步长0.05\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0\n",
    "    for t in thresholds:\n",
    "        predictions = [\n",
    "            1 if sid.polarity_scores(text)['compound'] >= t else 0 \n",
    "            for text in texts\n",
    "        ]\n",
    "        current_f1 = f1_score(y_true, predictions)\n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            best_thresh = t\n",
    "    return best_thresh, best_f1  # 返回阈值和对应的F1分数\n",
    "\n",
    "# 使用验证集寻找最佳阈值\n",
    "best_threshold, best_f1 = find_best_threshold(val_labels, cleaned_val_texts)\n",
    "print(f\"Mejor umbral en validación: {best_threshold:.2f} (F1-Score: {best_f1:.4f})\")\n",
    "\n",
    "# === 4. 最终预测（测试集） ===\n",
    "vader_labels = [\n",
    "    1 if sid.polarity_scores(text)['compound'] >= best_threshold else 0\n",
    "    for text in cleaned_test_texts\n",
    "]\n",
    "\n",
    "# === 5. 计算指标 ===\n",
    "accuracy = accuracy_score(test_labels, vader_labels)\n",
    "precision = precision_score(test_labels, vader_labels)\n",
    "recall = recall_score(test_labels, vader_labels)\n",
    "f1 = f1_score(test_labels, vader_labels)\n",
    "\n",
    "print(\"\\n=== Rendimiento final de VADER en IMDb ===\")\n",
    "print(f\"Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50445c8b23ed7223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T20:22:33.899437Z",
     "start_time": "2025-03-25T20:22:22.426595200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de casos de error: 7207 (Tasa de error: 28.83%)\n",
      "Primeros 5 casos de error:\n",
      "\n",
      "Caso 1:\n",
      "Real: 1, Predicción: 0 (Puntuación: -0.12)\n",
      "Texto original: I felt this film did have many good qualities. The cinematography was certainly different exposing t...\n",
      "Texto limpiado: i felt this film did have many good qualities the cinematography was certainly different exposing th...\n",
      "\n",
      "Caso 2:\n",
      "Real: 1, Predicción: 0 (Puntuación: -0.30)\n",
      "Texto original: This movie is amazing because the fact that the real people portray themselves and their real life e...\n",
      "Texto limpiado: this movie is amazing because the fact that the real people portray themselves and their real life e...\n",
      "\n",
      "Caso 3:\n",
      "Real: 1, Predicción: 0 (Puntuación: -0.78)\n",
      "Texto original: \"Night of the Hunted\" stars French porn star Brigitte Lahaie.In fact,many of the cast members in thi...\n",
      "Texto limpiado: night of the hunted stars french porn star brigitte lahaiein factmany of the cast members in this sl...\n",
      "\n",
      "Caso 4:\n",
      "Real: 1, Predicción: 0 (Puntuación: -0.97)\n",
      "Texto original: Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's fi...\n",
      "Texto limpiado: warner brothers tampered considerably with american history in big trail director raoul walshs first...\n",
      "\n",
      "Caso 5:\n",
      "Real: 1, Predicción: 0 (Puntuación: -0.79)\n",
      "Texto original: BEING Warner Brothers' second historical drama featuring Civil War and Battle of the Little Big Horn...\n",
      "Texto limpiado: being warner brothers second historical drama featuring civil war and battle of the little big horn ...\n"
     ]
    }
   ],
   "source": [
    "# === 6. Análisis de casos de error ===\n",
    "def analyze_errors(true_labels, pred_labels, texts):\n",
    "    errors = []\n",
    "    for i in range(len(true_labels)):\n",
    "        if pred_labels[i] != true_labels[i]:\n",
    "            errors.append({\n",
    "                'Texto': texts[i],  # Traducido de '文本'\n",
    "                'Texto limpiado': cleaned_test_texts[i],  # Traducido de '清洗后文本'\n",
    "                'Etiqueta real': true_labels[i],  # Traducido de '真实标签'\n",
    "                'Etiqueta predicha': pred_labels[i],  # Traducido de '预测标签'\n",
    "                'Puntuación de sentimiento': sid.polarity_scores(cleaned_test_texts[i])['compound']  # Traducido de '情感分数'\n",
    "            })\n",
    "    return errors\n",
    "\n",
    "# Obtener casos de error\n",
    "error_cases = analyze_errors(test_labels, vader_labels, test_texts)\n",
    "\n",
    "# Mostrar los primeros 5 casos de error\n",
    "print(f\"\\nCantidad de casos de error: {len(error_cases)} (Tasa de error: {len(error_cases)/len(test_labels):.2%})\")  # Traducido de \"错误案例数量\" y \"错误率\"\n",
    "print(\"Primeros 5 casos de error:\")  # Traducido de \"前5个错误案例\"\n",
    "for idx, err in enumerate(error_cases[:5], 1):\n",
    "    print(f\"\\nCaso {idx}:\")\n",
    "    print(f\"Real: {err['Etiqueta real']}, Predicción: {err['Etiqueta predicha']} (Puntuación: {err['Puntuación de sentimiento']:.2f})\")  # Traducido de \"真实\", \"预测\", \"分数\"\n",
    "    print(f\"Texto original: {err['Texto'][:100]}...\")  # Traducido de \"原始文本\"\n",
    "    print(f\"Texto limpiado: {err['Texto limpiado'][:100]}...\")  # Traducido de \"清洗后文本\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd7b7a1e43a9a93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:48:53.900049100Z",
     "start_time": "2025-03-25T19:48:42.547716300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW+NB - Accuracy: 0.8413 | Precision: 0.8632 | Recall: 0.8112 | F1-Score: 0.8364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# === 优化参数 ===\n",
    "count_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=20000,\n",
    "    stop_words='english',\n",
    "    min_df=5\n",
    ")\n",
    "nb = MultinomialNB(alpha=0.1)\n",
    "\n",
    "# 构建管道\n",
    "bow_nb_model = make_pipeline(count_vectorizer, nb)\n",
    "\n",
    "# 训练模型\n",
    "bow_nb_model.fit(train_texts, train_labels)\n",
    "\n",
    "# 预测与评估\n",
    "bow_nb_labels = bow_nb_model.predict(test_texts)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, bow_nb_labels)\n",
    "precision = precision_score(test_labels, bow_nb_labels)\n",
    "recall = recall_score(test_labels, bow_nb_labels)\n",
    "f1 = f1_score(test_labels, bow_nb_labels)\n",
    "\n",
    "print(f\"BoW+NB - Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8b90e5c3ccf62e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:49:34.053925900Z",
     "start_time": "2025-03-25T19:49:34.017945400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número total de errores: 3967 (tasa de error: 15.87%)\n",
      "\n",
      "Ejemplos de casos de error:\n",
      "Caso 1:\n",
      "Etiqueta real: 1, Prediction: 0\n",
      "Texto original: 'My wife is a mental health therapist and we watched it from beginning to end. I am the typical man a'\n",
      "\n",
      "Caso 2:\n",
      "Etiqueta real: 1, Prediction: 0\n",
      "Texto original: \"While I can't say whether or not Larry Hama ever saw any of the old cartoons, I would think that wri\"\n",
      "\n",
      "Caso 3:\n",
      "Etiqueta real: 1, Prediction: 0\n",
      "Texto original: 'Why does everyone feel they have to constantly put this movie down? It is cute and funny (exactly wh'\n",
      "\n",
      "Caso 4:\n",
      "Etiqueta real: 1, Prediction: 0\n",
      "Texto original: \"Madonna gets into action, again and she fails again! Who's That Girl was released just one year afte\"\n",
      "\n",
      "Caso 5:\n",
      "Etiqueta real: 1, Prediction: 0\n",
      "Texto original: \"So, Madonna isn't Meryl Streep. Still, this is one of her first films and a comedy at that. Give her\"\n"
     ]
    }
   ],
   "source": [
    "# === 错误案例分析 ===\n",
    "errors = []\n",
    "for i in range(len(test_labels)):\n",
    "    if bow_nb_labels[i] != test_labels[i]:\n",
    "        errors.append({\n",
    "            'Text': test_texts[i],\n",
    "            'True': test_labels[i],\n",
    "            'Predicted': bow_nb_labels[i]\n",
    "        })\n",
    "\n",
    "# 输出总错误数和错误率\n",
    "total_errors = len(errors)\n",
    "error_rate = total_errors / len(test_labels) * 100\n",
    "print(f\"\\nNúmero total de errores: {total_errors} (tasa de error: {error_rate:.2f}%)\")\n",
    "\n",
    "# 显示前5个错误案例\n",
    "print(\"\\nEjemplos de casos de error:\")\n",
    "for idx, err in enumerate(errors[:5], 1):\n",
    "    print(f\"Caso {idx}:\")\n",
    "    print(f\"Etiqueta real: {err['True']}, Prediction: {err['Predicted']}\")\n",
    "    print(f\"Texto original: {err['Text'][:100]!r}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a4654424de648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:43:05.826700400Z",
     "start_time": "2025-03-25T19:42:54.946382Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF+SVM - Accuracy: 0.8805, Precision: 0.8770, Recall: 0.8851, F1 Score: 0.8810\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ====== 关键参数设置 ======\n",
    "# 1. TF-IDF参数\n",
    "tfidf_params = {\n",
    "    \"ngram_range\": (1, 2),\n",
    "    \"max_features\": 20000,  # 放宽至10,000\n",
    "    \"stop_words\": \"english\",  # 基础停用词过滤\n",
    "    \"min_df\": 5,            # 允许出现2次的词\n",
    "    \"max_df\": 0.8           # 保留更多常见词\n",
    "}\n",
    "\n",
    "# 2. SVM参数\n",
    "svm_params = {\n",
    "    \"C\": 0.1,                 # 正则化强度（值越小正则化越强）\n",
    "    \"class_weight\": \"balanced\", # 自动平衡类别权重（IMDB数据均衡可省略）\n",
    "}\n",
    "\n",
    "# ====== 修改后的管道构建 ======\n",
    "tfidf_svm_model = make_pipeline(\n",
    "    TfidfVectorizer(**tfidf_params),  # 注入TF-IDF参数\n",
    "    LinearSVC(**svm_params)           # 注入SVM参数\n",
    ")\n",
    "\n",
    "# ====== 训练与测试（保持不变） ======\n",
    "tfidf_svm_model.fit(train_texts, train_labels)\n",
    "tfidf_svm_labels = tfidf_svm_model.predict(test_texts)\n",
    "\n",
    "# ====== 计算指标 ======\n",
    "accuracy_tfidf_svm = accuracy_score(test_labels, tfidf_svm_labels)\n",
    "precision_tfidf_svm = precision_score(test_labels, tfidf_svm_labels)\n",
    "recall_tfidf_svm = recall_score(test_labels, tfidf_svm_labels)\n",
    "f1_tfidf_svm = f1_score(test_labels, tfidf_svm_labels)\n",
    "\n",
    "print(f\"TF-IDF+SVM - Accuracy: {accuracy_tfidf_svm:.4f}, Precision: {precision_tfidf_svm:.4f}, Recall: {recall_tfidf_svm:.4f}, F1 Score: {f1_tfidf_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c57fe3e1b82f3fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:50:07.196086100Z",
     "start_time": "2025-03-25T19:50:07.175779900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número total de errores: 2988 (tasa de error: 11.95%)\n",
      "\n",
      "Ejemplos de casos de error:\n",
      "Caso 1:\n",
      "Etiqueta real: 1, Prediction: 0\n",
      "Texto original: 'My wife is a mental health therapist and we watched it from beginning to end. I am the typical man a'\n",
      "\n",
      "Caso 2:\n",
      "Etiqueta real: 1, Prediction: 0\n",
      "Texto original: \"I have certainly not seen all of Jean Rollin's films, but they mostly seem to be bloody vampire nake\"\n",
      "\n",
      "Caso 3:\n",
      "Etiqueta real: 1, Prediction: 0\n",
      "Texto original: \"While I can't say whether or not Larry Hama ever saw any of the old cartoons, I would think that wri\"\n",
      "\n",
      "Caso 4:\n",
      "Etiqueta real: 1, Prediction: 0\n",
      "Texto original: 'Naturally, along with everyone else, I was primed to expect a lot of Hollywood fantasy revisionism i'\n",
      "\n",
      "Caso 5:\n",
      "Etiqueta real: 1, Prediction: 0\n",
      "Texto original: \"For late-80s cheese, this really isn't so bad. There are a lot of pretty funny throwaway one-liners \"\n"
     ]
    }
   ],
   "source": [
    "# === 错误案例分析 ===\n",
    "errors = []\n",
    "for i in range(len(test_labels)):\n",
    "    if tfidf_svm_labels[i] != test_labels[i]:\n",
    "        errors.append({\n",
    "            'Text': test_texts[i],\n",
    "            'True': test_labels[i],\n",
    "            'Predicted': tfidf_svm_labels[i]\n",
    "        })\n",
    "\n",
    "# 输出总错误数和错误率\n",
    "total_errors = len(errors)\n",
    "error_rate = total_errors / len(test_labels) * 100\n",
    "print(f\"\\nNúmero total de errores: {total_errors} (tasa de error: {error_rate:.2f}%)\")\n",
    "\n",
    "# 显示前5个错误案例\n",
    "print(\"\\nEjemplos de casos de error:\")\n",
    "for idx, err in enumerate(errors[:5], 1):\n",
    "    print(f\"Caso {idx}:\")\n",
    "    print(f\"Etiqueta real: {err['True']}, Prediction: {err['Predicted']}\")\n",
    "    print(f\"Texto original: {err['Text'][:100]!r}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
